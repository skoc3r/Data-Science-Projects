import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import numpy as np


data = pd.read_csv('/home/squid/Downloads/archive/WA_Fn-UseC_-Telco-Customer-Churn.csv')

print(data.head())

# Copy the data
data_copy = data.copy()

# Convert 'TotalCharges' to numeric, set errors='coerce' to handle non-numeric values
data_copy['TotalCharges'] = pd.to_numeric(data_copy['TotalCharges'], errors='coerce')

# Impute missing values in 'TotalCharges' using the median
imputer = SimpleImputer(strategy='median')
data_copy['TotalCharges'] = imputer.fit_transform(data_copy[['TotalCharges']])

# Drop the 'customerID' column as it is not useful for the model
data_copy.drop(['customerID'], axis=1, inplace=True)

# Map 'Churn' values to binary (Yes -> 1, No -> 0)
data_copy['Churn'] = data_copy['Churn'].map({'Yes': 1, 'No': 0})

# Convert all categorical variables to dummy/indicator variables
data_copy = pd.get_dummies(data_copy, drop_first=True)

# Check for any remaining missing values and impute if necessary
data_copy.fillna(data_copy.median(), inplace=True)

# Split the data into X and Y
X = data_copy.drop('Churn', axis=1)
y = data_copy['Churn']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the RandomForestClassifier
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict the test set results
y_pred = model.predict(X_test)

# Calculate accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# Confusion matrix
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Classification report
print("Classification Report:\n", classification_report(y_test, y_pred))

importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 6))
plt.title("Feature Importance")
plt.bar(range(X_train.shape[1]), importances[indices], align="center")
plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)
plt.tight_layout()
plt.show()
